{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "WaveFormProjectFinal.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBMVFkm5d9Je"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#Reading the data as a dataframe\n",
        "df = pd.read_csv(\"waveform.data\", sep=\",\", names=['d1', 'd2','d3','d4','d5','d6','d7','d8','d9','d10','d11','d12','d13','d14','d15','d16','d17','d18','d19','d20','d21','d22'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7QUkZiId9Jn"
      },
      "source": [
        "# Splitting data to features and Traget Data\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, 21].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk55wxz9d9Jt"
      },
      "source": [
        "#Tuning the hyper parameter k\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#create a new knn model\n",
        "knn2=KNeighborsClassifier()\n",
        "\n",
        "#create a dictionary of all values we want to test for n_neighbors - check k values from 1 to 100\n",
        "param_grid={'n_neighbors':np.arange(1,100)}\n",
        "\n",
        "#Use gridsearch to test all values for n_neighbors\n",
        "knn_gscv=GridSearchCV(knn2,param_grid,cv=5,return_train_score=True)\n",
        "\n",
        "#fit model to data\n",
        "knn_gscv.fit(X,Y)\n",
        "\n",
        "print(\"The Best K Value is\",knn_gscv.best_params_,\" With a score of \",knn_gscv.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w9buiaJd9J2"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x = np.linspace(0, 100, 99)\n",
        "y = knn_gscv.cv_results_['mean_test_score']\n",
        "\n",
        "plt.axvline(x=58)\n",
        "plt.axhline(y=0.8586)\n",
        "plt.plot(x, y, '-ok', color='black');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPSP8mked9J9"
      },
      "source": [
        "knn_gscv.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeL5OF4Yd9KC"
      },
      "source": [
        "knn_gscv.cv_results_['mean_test_score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Jc0SvId9KJ"
      },
      "source": [
        "#Secound Step - Analysis of the bias-variance trade-off(Start with a very small training set(e.g 100 waves and a large k) and study the gap to the bayes error.)\n",
        "result=[];k=100\n",
        "for i in range(1,50):\n",
        "    data=df.copy()\n",
        "    data_train=data.sample(n=100*i,random_state=1)\n",
        "    data_test=data.drop(data_train.index)\n",
        "    #print(\"train shape is\",data_train.shape,\" Testing shape is \",data_test.shape)\n",
        "    data_train_x=data_train.iloc[:,:-1].values\n",
        "    data_train_y=data_train.iloc[:,21].values\n",
        "    data_test_x=data_test.iloc[:,:-1].values\n",
        "    data_test_y=data_test.iloc[:,21].values\n",
        "    \n",
        "    #from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(data_train_x)\n",
        "    X_train = scaler.transform(data_train_x)\n",
        "    X_test = scaler.transform(data_test_x)\n",
        "    \n",
        "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "    classifier.fit(X_train, data_train_y)\n",
        "    \n",
        "    y_pred = classifier.predict(X_test)\n",
        "    #print(\" for traning explaes of \",100*i,\" and k value of \",k,\" the score is\",accuracy_score(data_test_y, y_pred))\n",
        "    result.append(accuracy_score(data_test_y, y_pred))\n",
        "    k-=2\n",
        "print(result)\n",
        "len(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ipdHmKd9KR"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x = np.linspace(4, 100, 49)\n",
        "y = result\n",
        "\n",
        "plt.plot(x, y, '-ok', color='black');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgs_01a5d9KX"
      },
      "source": [
        "# Third - Redyce the complexity with the CNN and RNN algorithms. Compare with the Original dataset.\n",
        "\n",
        "#Performing RNN on the dataset\n",
        "#Randomly dividing dataset into 2 subsets\n",
        "RNN_data=df.copy()\n",
        "RNN_Set1=RNN_data.sample(frac=0.5,random_state=0)\n",
        "RNN_Set2=RNN_data.drop(RNN_Set1.index)\n",
        "\n",
        "#Resetting Index for Set1 and Set2\n",
        "RNN_Set1.reset_index(inplace=True,drop=True)\n",
        "RNN_Set2.reset_index(inplace=True,drop=True)\n",
        "S1_X=RNN_Set1.iloc[:,:-1].values\n",
        "S1_Y=RNN_Set1.iloc[:,21].values\n",
        "S2_X=RNN_Set2.iloc[:,:-1].values\n",
        "S2_Y=RNN_Set2.iloc[:,21].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s36fWjA7d9Kc"
      },
      "source": [
        "classifier1=KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "#Function to train data set s1\n",
        "def FitS1():\n",
        "    scaler=StandardScaler()\n",
        "    scaler.fit(S1_X)\n",
        "    S1_Xtrain=scaler.transform(S1_X)\n",
        "    classifier1.fit(S1_Xtrain,S1_Y)\n",
        "    ypred=classifier1.predict(S2_X)\n",
        "    return ypred\n",
        "    \n",
        "#Function to train data set S2\n",
        "def FitS2():\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(S2_X)\n",
        "    S2_Xtrain=scaler.transform(S2_X)\n",
        "    classifier1.fit(S2_Xtrain,S2_Y)\n",
        "    ypred=classifier1.predict(S1_X)\n",
        "    return ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoFt79kTd9Kh"
      },
      "source": [
        "#Algorithm for RNN\n",
        "stabilization=0;t=0\n",
        "while stabilization==0:\n",
        "    print(\"iteration number \",t);t+=1;stabilization=1\n",
        "    #resetting the index before every iteration\n",
        "    RNN_Set1.reset_index(inplace=True,drop=True)\n",
        "    RNN_Set2.reset_index(inplace=True,drop=True)\n",
        "    #seperating features from target for S1 and S2\n",
        "    S1_X=RNN_Set1.iloc[:,:-1].values\n",
        "    S1_Y=RNN_Set1.iloc[:,21].values\n",
        "    S2_X=RNN_Set2.iloc[:,:-1].values\n",
        "    S2_Y=RNN_Set2.iloc[:,21].values\n",
        "    #Algorithm for RNN\n",
        "    ypred=FitS2()\n",
        "    for i in range(len(ypred)):\n",
        "        if ypred[i]!=S1_Y[i]:\n",
        "            RNN_Set1.drop(i,inplace=True)\n",
        "            stabilization=0\n",
        "    ypred=FitS1()\n",
        "    for i in range(len(ypred)):\n",
        "        if ypred[i]!=S2_Y[i]:\n",
        "            RNN_Set2.drop(i,inplace=True)\n",
        "            stabilization=0\n",
        "    if stabilization==1:print(\"reached stabilization\")\n",
        "RNN=pd.concat([RNN_Set1,RNN_Set2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOCQQ6rd9Km"
      },
      "source": [
        "RNN.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcI0WWkzd9Ku"
      },
      "source": [
        "#Initialization for CNN\n",
        "\n",
        "#Resetting the index for RNN output\n",
        "RNN_data.reset_index(inplace=True,drop=True)\n",
        "\n",
        "#Retriving column names\n",
        "columnlist=list(RNN.columns)\n",
        "\n",
        "#Intializing Storage and Dustbin\n",
        "Storage=pd.DataFrame(columns=columnlist)\n",
        "Dustbin=pd.DataFrame(columns=columnlist)\n",
        "\n",
        "#Intializing a random value\n",
        "randompick=RNN.sample(n=1,random_state=1)\n",
        "randompick.reset_index(inplace=True,drop=True)\n",
        "\n",
        "#Initializing Storage\n",
        "Storage=Storage.append(randompick)\n",
        "\n",
        "#Splitting features from Target\n",
        "X_set=RNN.iloc[:,:-1].values\n",
        "Y_set=RNN.iloc[:,21].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chc2uIOZd9Kz"
      },
      "source": [
        "#Algorithm for CNN to train Storage\n",
        "def FitStorage(Storage):\n",
        "    Storage.reset_index(inplace=True,drop=True)\n",
        "    classifier1=KNeighborsClassifier(n_neighbors=1)\n",
        "    storage_x=Storage.iloc[:,:-1].values\n",
        "    storage_y=Storage.iloc[:,21].values\n",
        "    scaler=StandardScaler()\n",
        "    scaler.fit(storage_x)\n",
        "    train=scaler.transform(storage_x)\n",
        "    classifier1.fit(train,storage_y)\n",
        "    ypred=classifier1.predict(X_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60fwkQp0d9K4"
      },
      "source": [
        "#Algorithm for CNN\n",
        "t=0;stabilization=0\n",
        "while stabilization==0:\n",
        "    stabilization=1\n",
        "    print(\"Iteration \",t);t+=1\n",
        "    print(\"Storage dimensions are \",Storage.shape,\" Dustbin Dimensions are \",Dustbin.shape)\n",
        "    for i in range(len(RNN)):\n",
        "        ypred=FitStorage(Storage)\n",
        "        if(ypred[i]==Y_set[i]):\n",
        "            Dustbin=Dustbin.append(RNN.iloc[i,:])\n",
        "        else:\n",
        "            Storage=Storage.append(RNN.iloc[i,:])\n",
        "            stabilization=0\n",
        "    if stabilization==1: print(\"Storage Stabilized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXNry4xd9K_"
      },
      "source": [
        "Storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqzvML2fd9LD"
      },
      "source": [
        "RNN.tail(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54hSstu_d9LI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbBSO9xed9LQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEEOtLb5d9LV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}